{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(arr, arrY, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "    \n",
    "    batch_size_total = batch_size * seq_length\n",
    "    # total number of batches we can make\n",
    "    n_batches = len(arr)//batch_size_total\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    arrY = arrY[:n_batches * batch_size_total]\n",
    "    \n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    arrY = arrY.reshape((batch_size, -1))\n",
    "    \n",
    "    # iterate through the array, one sequence at a time\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "\n",
    "        y = arrY[:, n:n+seq_length]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputData, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        # creating character dictionaries\n",
    "#         self.chars = tokens\n",
    "#         self.int2char = dict(enumerate(self.chars))\n",
    "#         self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        ## TODO: define the LSTM\n",
    "        \n",
    "        print(\"Input data shape\", len(inputData[0]))\n",
    "        \n",
    "        self.lstm = nn.LSTM(len(inputData[0]), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        ## TODO: define a dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        ## TODO: define the final, fully-connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(inputData[0]))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        ''' Forward pass through the network. \n",
    "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
    "                \n",
    "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
    "        r_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        ## TODO: pass through a dropout layer\n",
    "        out = self.dropout(r_output)\n",
    "        \n",
    "        # Stack up LSTM outputs using view\n",
    "        # you may need to use contiguous to reshape the output\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        ## TODO: put x through the fully-connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # return the final output and the hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataX,dataY, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(dataX)*(1-val_frac))\n",
    "    data, val_data = dataX[:val_idx], dataX[val_idx:]\n",
    "    dataY, val_Y = dataY[:val_idx], dataY[val_idx:]\n",
    "    \n",
    "    \n",
    "#     print(\"val data size : \", val_data.shape)\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    dataSize = len(data[0]) # single data shape\n",
    "#     n_char\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "#         print(\"Data X shape\", data.shape)\n",
    "#         print(\"Data Y shape\", dataY.shape)\n",
    "        \n",
    "        \n",
    "        for x, y in get_batches(data,dataY, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            x = np.expand_dims(x, axis=2)\n",
    "#             y = np.expand_dims(y, axis=2)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            y= np.reshape(y,(batch_size*seq_length,1)).astype(np.float32)\n",
    "            \n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            \n",
    "    \n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "\n",
    "            output, h = net(inputs, h)\n",
    "\n",
    "            np.set_printoptions(suppress=True)\n",
    "\n",
    "            numpyOutput = output.detach().numpy()\n",
    "            numpyTarget =  targets.detach().numpy()\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, val_Y, batch_size, seq_length):\n",
    "\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "\n",
    "                    y= np.reshape(y,(batch_size*seq_length,1)).astype(np.float32)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    \n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets)\n",
    "                    print(\"Loss : \", val_loss.item())\n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train() # reset to train mode after iterationg through validation data\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=512\n",
    "n_layers=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# how many time steps/data pts are in one batch of data\n",
    "seq_length = 1000\n",
    "\n",
    "# generate evenly spaced data pts\n",
    "time_steps = np.linspace(0, np.pi/2, seq_length + 1)\n",
    "data = np.sin(time_steps)\n",
    "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
    "\n",
    "x = data[:-1] # all but the last piece of data\n",
    "y = data[1:] # all but the first\n",
    "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
    "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
    "# plt.plot(time_steps[1:], data[:], 'b.', label='original, y')\n",
    "\n",
    "x = np.float32(x)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = x\n",
    "dataX.shape\n",
    "\n",
    "dataY = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataX[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Call and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape 1\n",
      "CharRNN(\n",
      "  (lstm): LSTM(1, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = CharRNN(dataX, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  0.5532101392745972\n",
      "Epoch: 1/20... Step: 10... Loss: 0.1679... Val Loss: 0.5532\n",
      "Loss :  0.4502831995487213\n",
      "Epoch: 2/20... Step: 20... Loss: 0.0886... Val Loss: 0.4503\n",
      "Loss :  0.4919227659702301\n",
      "Epoch: 3/20... Step: 30... Loss: 0.0395... Val Loss: 0.4919\n",
      "Loss :  0.30859747529029846\n",
      "Epoch: 4/20... Step: 40... Loss: 0.0647... Val Loss: 0.3086\n",
      "Loss :  0.2939322888851166\n",
      "Epoch: 5/20... Step: 50... Loss: 0.0306... Val Loss: 0.2939\n",
      "Loss :  0.21916517615318298\n",
      "Epoch: 6/20... Step: 60... Loss: 0.0163... Val Loss: 0.2192\n",
      "Loss :  0.24403426051139832\n",
      "Epoch: 7/20... Step: 70... Loss: 0.0085... Val Loss: 0.2440\n",
      "Loss :  0.1566176414489746\n",
      "Epoch: 8/20... Step: 80... Loss: 0.0054... Val Loss: 0.1566\n",
      "Loss :  0.22324085235595703\n",
      "Epoch: 9/20... Step: 90... Loss: 0.0318... Val Loss: 0.2232\n",
      "Loss :  0.13845029473304749\n",
      "Epoch: 10/20... Step: 100... Loss: 0.0488... Val Loss: 0.1385\n",
      "Loss :  0.15260443091392517\n",
      "Epoch: 10/20... Step: 110... Loss: 0.0071... Val Loss: 0.1526\n",
      "Loss :  0.16438640654087067\n",
      "Epoch: 11/20... Step: 120... Loss: 0.0081... Val Loss: 0.1644\n",
      "Loss :  0.10141462087631226\n",
      "Epoch: 12/20... Step: 130... Loss: 0.0144... Val Loss: 0.1014\n",
      "Loss :  0.10804654657840729\n",
      "Epoch: 13/20... Step: 140... Loss: 0.0039... Val Loss: 0.1080\n",
      "Loss :  0.09879578649997711\n",
      "Epoch: 14/20... Step: 150... Loss: 0.0025... Val Loss: 0.0988\n",
      "Loss :  0.06642871350049973\n",
      "Epoch: 15/20... Step: 160... Loss: 0.0060... Val Loss: 0.0664\n",
      "Loss :  0.05216079205274582\n",
      "Epoch: 16/20... Step: 170... Loss: 0.0038... Val Loss: 0.0522\n",
      "Loss :  0.04822099953889847\n",
      "Epoch: 17/20... Step: 180... Loss: 0.0022... Val Loss: 0.0482\n",
      "Loss :  0.04992411285638809\n",
      "Epoch: 18/20... Step: 190... Loss: 0.0044... Val Loss: 0.0499\n",
      "Loss :  0.0500270314514637\n",
      "Epoch: 19/20... Step: 200... Loss: 0.0064... Val Loss: 0.0500\n",
      "Loss :  0.04665911942720413\n",
      "Epoch: 20/20... Step: 210... Loss: 0.0164... Val Loss: 0.0467\n",
      "Loss :  0.039173539727926254\n",
      "Epoch: 20/20... Step: 220... Loss: 0.0034... Val Loss: 0.0392\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_length = 5\n",
    "n_epochs = 20 # start smaller if you are just testing initial behavior\n",
    "\n",
    "# train the model\n",
    "train(net, dataX,dataY, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lstm_motion_predict'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),}\n",
    "\n",
    "with open(model_name, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, hidden, inputX, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        x = inputX\n",
    "        \n",
    "        x = x.reshape((1,1,1))\n",
    "        print(\"Input Data \", x)\n",
    "        \n",
    "        \n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        h = tuple([each.data for each in hidden])\n",
    "        out, h = net(inputs, h)\n",
    "        return out,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data  [[[0.5]]]\n",
      "tensor([[0.4602]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "dataTest = [0.5]\n",
    "dataTest = np.asarray(dataTest,dtype=np.float32)\n",
    "net.eval()\n",
    "h = net.init_hidden(1)\n",
    "out,h= predict(net,h,dataTest)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data  [[[0.]]]\n",
      "Input Data  [[[0.02690065]]]\n",
      "Input Data  [[[-0.00399707]]]\n",
      "Input Data  [[[-0.00522598]]]\n",
      "Input Data  [[[0.00651087]]]\n",
      "Input Data  [[[0.02381461]]]\n",
      "Input Data  [[[0.04454361]]]\n",
      "Input Data  [[[0.06692198]]]\n",
      "Input Data  [[[0.08891285]]]\n",
      "Input Data  [[[0.10891905]]]\n",
      "Input Data  [[[0.12604406]]]\n",
      "Input Data  [[[0.13996187]]]\n",
      "Input Data  [[[0.15072258]]]\n",
      "Input Data  [[[0.1585992]]]\n",
      "Input Data  [[[0.16397788]]]\n",
      "Input Data  [[[0.16728222]]]\n",
      "Input Data  [[[0.16892642]]]\n",
      "Input Data  [[[0.16928904]]]\n",
      "Input Data  [[[0.16870117]]]\n",
      "Input Data  [[[0.167443]]]\n",
      "Input Data  [[[0.1657455]]]\n",
      "Input Data  [[[0.16379455]]]\n",
      "Input Data  [[[0.16173625]]]\n",
      "Input Data  [[[0.15968229]]]\n",
      "Input Data  [[[0.15771507]]]\n",
      "Input Data  [[[0.15589245]]]\n",
      "Input Data  [[[0.15425195]]]\n",
      "Input Data  [[[0.15281448]]]\n",
      "Input Data  [[[0.1515877]]]\n",
      "Input Data  [[[0.15056883]]]\n",
      "Input Data  [[[0.14974754]]]\n",
      "Input Data  [[[0.14910787]]]\n",
      "Input Data  [[[0.1486304]]]\n",
      "Input Data  [[[0.14829376]]]\n",
      "Input Data  [[[0.14807612]]]\n",
      "Input Data  [[[0.14795597]]]\n",
      "Input Data  [[[0.14791326]]]\n",
      "Input Data  [[[0.1479296]]]\n",
      "Input Data  [[[0.1479888]]]\n",
      "Input Data  [[[0.14807697]]]\n",
      "Input Data  [[[0.14818257]]]\n",
      "Input Data  [[[0.14829627]]]\n",
      "Input Data  [[[0.14841084]]]\n",
      "Input Data  [[[0.1485209]]]\n",
      "Input Data  [[[0.14862269]]]\n",
      "Input Data  [[[0.14871377]]]\n",
      "Input Data  [[[0.1487929]]]\n",
      "Input Data  [[[0.14885963]]]\n",
      "Input Data  [[[0.14891423]]]\n",
      "Input Data  [[[0.14895743]]]\n",
      "Input Data  [[[0.14899027]]]\n",
      "Input Data  [[[0.14901401]]]\n",
      "Input Data  [[[0.14902999]]]\n",
      "Input Data  [[[0.14903946]]]\n",
      "Input Data  [[[0.14904378]]]\n",
      "Input Data  [[[0.14904408]]]\n",
      "Input Data  [[[0.14904135]]]\n",
      "Input Data  [[[0.14903659]]]\n",
      "Input Data  [[[0.1490305]]]\n",
      "Input Data  [[[0.14902368]]]\n",
      "Input Data  [[[0.14901666]]]\n",
      "Input Data  [[[0.14900982]]]\n",
      "Input Data  [[[0.14900339]]]\n",
      "Input Data  [[[0.14899756]]]\n",
      "Input Data  [[[0.14899242]]]\n",
      "Input Data  [[[0.14898807]]]\n",
      "Input Data  [[[0.14898442]]]\n",
      "Input Data  [[[0.14898153]]]\n",
      "Input Data  [[[0.14897926]]]\n",
      "Input Data  [[[0.14897761]]]\n",
      "Input Data  [[[0.14897643]]]\n",
      "Input Data  [[[0.14897572]]]\n",
      "Input Data  [[[0.14897533]]]\n",
      "Input Data  [[[0.1489752]]]\n",
      "Input Data  [[[0.14897528]]]\n",
      "Input Data  [[[0.14897554]]]\n",
      "Input Data  [[[0.14897586]]]\n",
      "Input Data  [[[0.14897625]]]\n",
      "Input Data  [[[0.14897667]]]\n",
      "Input Data  [[[0.14897709]]]\n",
      "Input Data  [[[0.14897747]]]\n",
      "Input Data  [[[0.14897783]]]\n",
      "Input Data  [[[0.14897814]]]\n",
      "Input Data  [[[0.14897843]]]\n",
      "Input Data  [[[0.14897862]]]\n",
      "Input Data  [[[0.14897883]]]\n",
      "Input Data  [[[0.14897896]]]\n",
      "Input Data  [[[0.14897907]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897919]]]\n",
      "Input Data  [[[0.14897923]]]\n",
      "Input Data  [[[0.14897926]]]\n",
      "Input Data  [[[0.14897926]]]\n",
      "Input Data  [[[0.14897926]]]\n",
      "Input Data  [[[0.14897926]]]\n",
      "Input Data  [[[0.14897925]]]\n",
      "Input Data  [[[0.14897923]]]\n",
      "Input Data  [[[0.14897923]]]\n",
      "Input Data  [[[0.14897923]]]\n",
      "Input Data  [[[0.1489792]]]\n",
      "Input Data  [[[0.1489792]]]\n",
      "Input Data  [[[0.14897919]]]\n",
      "Input Data  [[[0.14897917]]]\n",
      "Input Data  [[[0.14897917]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897916]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897911]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897913]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n",
      "Input Data  [[[0.14897914]]]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "startVal = 0\n",
    "for i in range(1000):\n",
    "    dataTest = []\n",
    "    dataTest.append(startVal)\n",
    "    dataTest = np.asarray(dataTest,dtype=np.float32)\n",
    "    \n",
    "    out,h = predict(net,h,dataTest)\n",
    "    \n",
    "    res = out.detach().numpy()\n",
    "    result.append(res[0][0])\n",
    "    startVal = res[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.asarray(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_steps[1:], dataX, 'r.', label='Ground Truth') # x\n",
    "plt.plot(time_steps[1:], result, 'b.', label='Inference') # y\n",
    "# plt.plot(time_steps[1:], data[:], 'b.', label='original, y')\n",
    "\n",
    "x = np.float32(x)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
